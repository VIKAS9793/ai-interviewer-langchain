# ğŸ¤– AI Technical Interviewer

<div align="center">

### **Professional technical interview simulation powered by local AI**

<div style="max-width: 1200px; margin: 20px auto; border-radius: 16px; overflow: hidden; box-shadow: 0 8px 32px rgba(0,0,0,0.12); background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 4px;">
  <img src="src/ai_interviewer/assets/banner.jpg" alt="AI Interviewer Banner" style="width: 100%; height: auto; border-radius: 12px; display: block;"/>
</div>

<br>

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-3776ab.svg?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-0.1.19-00d084.svg?style=for-the-badge&logo=graphql&logoColor=white)](https://github.com/langchain-ai/langgraph)
[![Ollama](https://img.shields.io/badge/Ollama-Llama%203.2%203B-ff6b35.svg?style=for-the-badge&logo=meta&logoColor=white)](https://ollama.ai/)
[![Gradio](https://img.shields.io/badge/Gradio-4.37.2-ff7c00.svg?style=for-the-badge&logo=gradio&logoColor=white)](https://gradio.app/)
[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-28a745.svg?style=for-the-badge&logo=checkmarx&logoColor=white)](#)

</div>

---

## ğŸ¯ **Executive Summary**

<div align="center">
<table>
<tr>
<td width="33%" align="center">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Robot/3D/robot_3d.png" width="60">
<br><strong>AI-Powered</strong><br>
<small>Advanced LangGraph state machines with local LLM</small>
</td>
<td width="33%" align="center">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Brain/3D/brain_3d.png" width="60">
<br><strong>Adaptive Intelligence</strong><br>
<small>Questions adjust based on performance</small>
</td>
<td width="33%" align="center">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Chart%20increasing/3D/chart_increasing_3d.png" width="60">
<br><strong>Professional Analysis</strong><br>
<small>Multi-dimensional evaluation & feedback</small>
</td>
</tr>
</table>
</div>

> ğŸš€ **A sophisticated AI interviewer that conducts professional technical interviews using LangGraph state machines, Ollama's llama3.2:3b, and ChromaDB vector storage.**

---

## âœ… **Requirements Compliance**

<div align="center">

### ğŸ¯ **MANDATORY Requirements - All Met**

<table>
<tr>
<td align="center">âœ…<br><strong>LangGraph</strong><br><small>Advanced state machine flow control</small></td>
<td align="center">âœ…<br><strong>Ollama + llama3.2:3b</strong><br><small>Local LLM (exactly as specified)</small></td>
<td align="center">âœ…<br><strong>3-5 Dynamic Questions</strong><br><small>AI-generated, adaptive questioning</small></td>
</tr>
<tr>
<td align="center">âœ…<br><strong>Intelligent Responses</strong><br><small>Smart branching based on performance</small></td>
<td align="center">âœ…<br><strong>Performance Summary</strong><br><small>Comprehensive evaluation and feedback</small></td>
<td align="center">âœ…<br><strong>Branching Logic</strong><br><small>Next question depends on previous answer</small></td>
</tr>
</table>

### ğŸ **BONUS Features - Exceeding Requirements**

<table>
<tr>
<td align="center">â­<br><strong>ChromaDB Vector Store</strong><br><small>Semantic question retrieval</small></td>
<td align="center">â­<br><strong>Multi-Dimensional Scoring</strong><br><small>6-dimension evaluation system</small></td>
<td align="center">â­<br><strong>Gradio Web Interface</strong><br><small>Professional chat-style UI</small></td>
<td align="center">â­<br><strong>Advanced Analytics</strong><br><small>Performance tracking and insights</small></td>
</tr>
</table>

</div>

---

## ğŸ¥ **Live Demo**

<div align="center">

### **Watch the AI Interviewer in Action!**

[![AI Interviewer Demo](https://img.youtube.com/vi/0M7M1Pn31vQ/maxresdefault.jpg)](https://youtu.be/0M7M1Pn31vQ)

**ğŸ“º Click above to watch the full walkthrough**

<details>
<summary>ğŸ¬ <strong>What's Covered in the Demo</strong></summary>

- ğŸ¯ Starting a new interview session
- âš¡ Dynamic question generation  
- ğŸ“Š Real-time answer evaluation
- ğŸ“ˆ Performance feedback and scoring
- ğŸ› ï¸ System navigation and features

</details>

</div>

---

## ğŸš€ **Quick Start**

<div align="center">

### **Get up and running in 3 simple steps!**

</div>

<table>
<tr>
<td width="33%">

### ğŸ“‹ **1. Prerequisites**

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull llama3.2:3b model
ollama pull llama3.2:3b

# Start Ollama service
ollama serve
```

</td>
<td width="33%">

### ğŸ’» **2. Installation** 

```bash
# Clone and setup
git clone <your-repo-url>
cd ai-interviewer-langchain

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

</td>
<td width="33%">

### ğŸŒŸ **3. Launch**

```bash
# Start the application
python main.py
```

<div align="center">
<br>
<strong>ğŸŒ Open your browser to:</strong><br>
<code>http://localhost:7860</code>
</div>

</td>
</tr>
</table>

---

## ğŸ—ï¸ **Architecture & Technology**

<div align="center">

### **Modern Tech Stack**

<table>
<tr>
<td align="center" width="16.66%">
<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="40"><br>
<strong>Python 3.11+</strong><br>
<small>Core Backend</small>
</td>
<td align="center" width="16.66%">
<img src="https://avatars.githubusercontent.com/u/126733545?s=200&v=4" width="40"><br>
<strong>LangGraph</strong><br>
<small>State Machine</small>
</td>
<td align="center" width="16.66%">
<img src="https://avatars.githubusercontent.com/u/151674099?s=200&v=4" width="40"><br>
<strong>Ollama</strong><br>
<small>Local LLM</small>
</td>
<td align="center" width="16.66%">
<img src="https://repository-images.githubusercontent.com/299195649/e5099b80-2906-11eb-9c3a-8e7a3b2c4f0a" width="40"><br>
<strong>ChromaDB</strong><br>
<small>Vector Store</small>
</td>
<td align="center" width="16.66%">
<img src="https://gradio.app/assets/img/logo.png" width="40"><br>
<strong>Gradio</strong><br>
<small>Web Interface</small>
</td>
<td align="center" width="16.66%">
<img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="40"><br>
<strong>Transformers</strong><br>
<small>Embeddings</small>
</td>
</tr>
</table>

</div>

### **System Architecture**

```mermaid
graph TB
    subgraph "ğŸ–¥ï¸ Frontend Layer"
        A[Gradio Web UI]
    end
    
    subgraph "ğŸ§  Control Layer" 
        B[LangGraph State Machine]
        C[Flow Controller]
    end
    
    subgraph "ğŸ¤– AI Layer"
        D[Ollama LLM<br/>llama3.2:3b]
        E[AI Interviewer Agent]
        F[Response Evaluator]
    end
    
    subgraph "ğŸ“Š Data Layer"
        G[ChromaDB Vector Store]
        H[Question Bank]
        I[Session Memory]
    end
    
    A --> B
    B --> C
    C --> E
    E --> D
    E --> F
    F --> G
    G --> H
    H --> I
    I --> B
    B --> A
    
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style B fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px  
    style D fill:#e8f5e8,stroke:#388e3c,stroke-width:3px
    style G fill:#fff3e0,stroke:#f57c00,stroke-width:3px
```

---

## âš¡ **Performance Overview**

<div align="center">

<table>
<tr>
<td width="50%">

### **ğŸ“Š Current Metrics**

| Metric | Value |
|--------|-------|
| â±ï¸ Response Time | 3-5 minutes |
| ğŸ’¾ RAM Required | 8GB minimum |
| ğŸ® VRAM Required | 4GB |
| ğŸ“¦ Model Size | ~2GB (quantized) |

</td>
<td width="50%">

### **ğŸš€ Cloud Benefits**

| Aspect | Improvement |
|--------|-------------|
| ğŸ”¥ Processing Speed | 5-10x faster |
| ğŸ§  Memory Capacity | 4-8x more |
| ğŸ”„ Concurrency | 10x+ parallel |
| ğŸ¯ Model Accuracy | Significantly better |

</td>
</tr>
</table>

</div>

### **Interview Flow Diagram**

```mermaid
stateDiagram-v2
    [*] --> Start
    Start --> SelectTopic
    SelectTopic --> FirstQuestion
    
    state "Interview Loop" as interview {
        FirstQuestion --> EvaluateAnswer
        EvaluateAnswer --> Decision
        
        state Decision {
            [*] --> CheckScore
            CheckScore -->|Score >= 7| HarderQuestion
            CheckScore -->|4 <= Score < 7| SimilarQuestion  
            CheckScore -->|Score < 4| EasierQuestion
        }
        
        HarderQuestion --> EvaluateAnswer
        SimilarQuestion --> EvaluateAnswer
        EasierQuestion --> EvaluateAnswer
    }
    
    Decision -->|5 Questions Complete| GenerateReport
    GenerateReport --> [*]
    
    style Start fill:#e8f5e8
    style GenerateReport fill:#e3f2fd
    style Decision fill:#fff3e0
```

---

## ğŸ§  **Intelligent Features**

<div align="center">

<table>
<tr>
<td width="50%" align="center">

### **ğŸ¯ Adaptive Question Generation**

<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Target/3D/target_3d.png" width="80">

âœ¨ **Dynamic Difficulty Adjustment**<br>
ğŸ§© **Context-Aware Questions**<br>  
ğŸ“ **5 Technical Domains**<br>
ğŸ” **Expert-Level Content**

</td>
<td width="50%" align="center">

### **ğŸ“Š Multi-Dimensional Evaluation**

<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Bar%20chart/3D/bar_chart_3d.png" width="80">

ğŸ¯ **Technical Accuracy**<br>
ğŸ§  **Conceptual Understanding**<br>
ğŸ’¡ **Practical Application**<br>
ğŸ’¬ **Communication Clarity**

</td>
</tr>
</table>

</div>

### **Evaluation Criteria**

```python
evaluation_dimensions = {
    "ğŸ¯ technical_accuracy": "Correctness and precision of answers",
    "ğŸ§  conceptual_understanding": "Depth of theoretical knowledge", 
    "ğŸ’¡ practical_application": "Real-world applicability and examples",
    "ğŸ’¬ communication_clarity": "Quality of explanation and articulation",
    "ğŸ“š depth_of_knowledge": "Understanding of advanced concepts",
    "ğŸ” problem_solving_approach": "Analytical thinking and methodology"
}
```

---

## ğŸ“š **Interview Specializations**

<div align="center">

<table>
<tr>
<td align="center" width="20%">
<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/javascript/javascript-original.svg" width="50"><br>
<strong>JavaScript/Frontend</strong><br>
<small>React, DOM, Async Patterns</small>
</td>
<td align="center" width="20%">
<img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" width="50"><br>
<strong>Python/Backend</strong><br>
<small>Django, APIs, Databases</small>
</td>
<td align="center" width="20%">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Robot/3D/robot_3d.png" width="50"><br>
<strong>Machine Learning</strong><br>
<small>Algorithms, Models, Deployment</small>
</td>
<td align="center" width="20%">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Building%20construction/3D/building_construction_3d.png" width="50"><br>
<strong>System Design</strong><br>
<small>Architecture, Scalability</small>
</td>
<td align="center" width="20%">
<img src="https://raw.githubusercontent.com/microsoft/fluentui-emoji/main/assets/Gear/3D/gear_3d.png" width="50"><br>
<strong>Algorithms & DS</strong><br>
<small>Complexity, Optimization</small>
</td>
</tr>
</table>

</div>

### **Sample Interview Progression**

<div align="center">

```mermaid
graph LR
    A[Question 1<br/>Easy: Explain var vs let] --> B[Score: 8/10<br/>Strong Fundamentals]
    B --> C[Question 2<br/>Hard: Event Loop Mechanics]
    C --> D[Score: 6/10<br/>Needs Clarification] 
    D --> E[Question 3<br/>Medium: Closures Example]
    E --> F[Adaptive Flow<br/>Continues Based on Performance]
    
    style A fill:#e8f5e8
    style C fill:#ffebee
    style E fill:#fff3e0
    style F fill:#e3f2fd
```

</div>

---

## ğŸ› ï¸ **Development & Customization**

<details>
<summary><strong>ğŸ”§ Adding New Topics</strong></summary>

```python
# In question_bank.py
new_topic_questions = [
    {
        "question": "Your custom interview question",
        "difficulty": "medium", 
        "concepts": ["concept1", "concept2"],
        "expected_answer": "Expected response outline"
    }
]
```

</details>

<details>
<summary><strong>âš–ï¸ Customizing Evaluation</strong></summary>

```python
# In evaluator.py - modify scoring weights
evaluation_weights = {
    "technical_accuracy": 0.30,      # Adjust weights
    "communication_clarity": 0.25,   # to match your needs  
    "practical_application": 0.20,
    # ... other dimensions
}
```

</details>

<details>
<summary><strong>ğŸ”„ Extending LangGraph Flow</strong></summary>

```python
# In flow_controller.py - add new states
workflow.add_node("custom_state", custom_function)
workflow.add_edge("evaluate_answer", "custom_state")
```

</details>

---

## ğŸ† **Success Metrics**

<div align="center">

### **âœ… Core Requirements Achievement**

<table>
<tr>
<td align="center">âœ…<br><strong>5 Dynamic Questions</strong><br><small>AI-generated by LLM</small></td>
<td align="center">âœ…<br><strong>Smart Branching</strong><br><small>Performance-based flow</small></td>
<td align="center">âœ…<br><strong>Detailed Summary</strong><br><small>Comprehensive feedback</small></td>
</tr>
<tr>
<td align="center">âœ…<br><strong>LangGraph Integration</strong><br><small>State machine control</small></td>
<td align="center">âœ…<br><strong>Local LLM</strong><br><small>Ollama llama3.2:3b</small></td>
<td align="center">âœ…<br><strong>Memory Management</strong><br><small>Full state tracking</small></td>
</tr>
</table>

### **â­ Bonus Achievements**

<table>
<tr>
<td align="center">ğŸ…<br><strong>Vector Database</strong><br><small>ChromaDB semantic search</small></td>
<td align="center">ğŸ…<br><strong>Web Interface</strong><br><small>Professional Gradio UI</small></td>
<td align="center">ğŸ…<br><strong>Analytics</strong><br><small>Real-time performance tracking</small></td>
<td align="center">ğŸ…<br><strong>Production Ready</strong><br><small>Enterprise-grade architecture</small></td>
</tr>
</table>

</div>

---

## ğŸš€ **Getting Started**

<div align="center">

### **ğŸ¯ Prerequisites Checklist**

- [ ] Python 3.11+ installed
- [ ] Ollama installed and running  
- [ ] llama3.2:3b model downloaded
- [ ] Git for repository cloning

### **ğŸ“¦ Installation Commands**

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/VIKAS9793/ai-interviewer-langchain.git
cd ai-interviewer-langchain

# 2ï¸âƒ£ Setup virtual environment  
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Launch the application
python main.py
```

### **ğŸŒ Access Your Interview Portal**
**Open: `http://localhost:7860`**

</div>

---

## ğŸ› ï¸ **Troubleshooting**

<details>
<summary><strong>ğŸ”§ Ollama Connection Issues</strong></summary>

```bash
# Check if Ollama is running
ollama list

# Start Ollama service  
ollama serve

# Download model if missing
ollama pull llama3.2:3b
```

</details>

<details>
<summary><strong>ğŸ—„ï¸ ChromaDB Problems</strong></summary>

```bash
# Clear ChromaDB cache
rm -rf ./chroma_db

# Restart application
python main.py
```

</details>

<details>
<summary><strong>ğŸŒ Web Interface Not Loading</strong></summary>

```bash
# Check port availability
netstat -an | grep 7860

# Use alternative port
python main.py --server-port 7861
```

</details>

---

## ğŸš€ **Future Roadmap**

<div align="center">

<table>
<tr>
<td width="50%">

### **ğŸ¯ Immediate Enhancements**

- [ ] ğŸ™ï¸ Voice interview capability
- [ ] ğŸ’» Code execution sandbox  
- [ ] ğŸ“¹ Interview recording/playback
- [ ] ğŸŒ Multi-language support

</td>
<td width="50%">

### **ğŸ”® Advanced Features**  

- [ ] ğŸ“ AI-powered interview coaching
- [ ] ğŸ¢ HR systems integration
- [ ] ğŸ“Š Advanced analytics dashboard
- [ ] ğŸ“± Mobile-responsive interface

</td>
</tr>
</table>

</div>

---

## ğŸ¤ **Contributing**

<div align="center">

**We welcome contributions! Here's how to get started:**

```mermaid
graph LR
    A[Fork Repository] --> B[Create Feature Branch]
    B --> C[Make Changes] 
    C --> D[Commit Changes]
    D --> E[Push to Branch]
    E --> F[Open Pull Request]
    
    style A fill:#e8f5e8
    style F fill:#e3f2fd
```

</div>

1. **ğŸ´ Fork the repository**
2. **ğŸŒ¿ Create your feature branch** (`git checkout -b feature/amazing-feature`)
3. **âœ… Commit your changes** (`git commit -m 'Add amazing feature'`)
4. **ğŸš€ Push to the branch** (`git push origin feature/amazing-feature`)
5. **ğŸ“ Open a Pull Request**

---

## ğŸ“„ **License**

<div align="center">

**MIT License** - See [LICENSE](LICENSE) file for details

---

<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; border-radius: 16px; color: white; margin: 20px 0;">

### **ğŸš€ Built with â¤ï¸ using cutting-edge AI technologies**

**LangGraph â€¢ Ollama â€¢ ChromaDB â€¢ Gradio â€¢ Python**

*Ready for production deployment and enterprise use cases*

</div>

**â­ If this project helped you, please give it a star!**

</div>