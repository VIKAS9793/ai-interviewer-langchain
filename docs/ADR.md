# üìã Architecture Decision Records (ADR)

> **Last Updated:** 2025-12-16

## 1. Cloud-First Deployment

**Status:** Accepted

**Context:** The project was originally designed for local execution with Ollama. However, HuggingFace Spaces provides free hosting with serverless GPU inference.

**Decision:** Adopt a **cloud-first architecture** using HuggingFace Inference API as the primary deployment target.

**Consequences:**
- ‚úÖ No local GPU required
- ‚úÖ Free hosting on HuggingFace Spaces
- ‚úÖ Automatic scaling
- ‚ö†Ô∏è Requires internet connectivity
- ‚ö†Ô∏è Subject to API rate limits

---

## 2. Single-Model Evaluation Strategy (Architecture Simplified)
**Status:** Accepted (Replaces Dual-Model)
**Context:** Multi-model inference (Mistral/Qwen) on Free Tier caused 500 errors ("Task not supported").
**Decision:** Standardize on **Meta-LLaMA-3** (or equivalent 8B model) for BOTH generation and evaluation.
**Consequences:**
- ‚úÖ 100% API Stability (No "Task not supported" errors)
- ‚úÖ Simplified Architecture (DRY)
- ‚ö†Ô∏è Sacrifices nuanced scoring of larger models for reliability

---

## 3. 1-5 Scale Instead of 1-10

**Status:** Accepted

**Context:** Research (Prometheus, FARE) shows that 1-5 scales yield more reliable and consistent LLM evaluations.

**Decision:** Use **1-5 scoring scale** internally, convert to 1-10 for UI display.

**Consequences:**
- ‚úÖ More consistent scores
- ‚úÖ Easier rubric definitions
- ‚úÖ Higher human correlation

---

## 4. Semantic Relevance Checking

**Status:** Accepted

**Context:** The AI was incorrectly scoring off-topic answers highly because heuristics only checked keywords.

**Decision:** Add **embedding-based semantic similarity** using Sentence Transformers.

**Consequences:**
- ‚úÖ Detects off-topic answers accurately
- ‚úÖ Cached embeddings for performance
- ‚ö†Ô∏è Additional dependency (sentence-transformers)

---

## 5. Micro-Kernel Architecture (v3.0)

**Status:** Accepted

**Context:** The `AutonomousInterviewer` class grew into a "God Class" (1200+ lines), making testing and maintenance difficult. File corruption issues highlighted the need for separation.

**Decision:** Refactor into a **Micro-Service Architecture**:
*   **Orchestrator:** `AutonomousInterviewer` (Stateless Controller).
*   **State:** `SessionManager` (Isolated Logic).
*   **Cognition:** `CognitiveModules` (RAG, Critic, Learner).

**Consequences:**
*   ‚úÖ **Testability:** Can verify `rag_service` without mocking the whole app.
*   ‚úÖ **Stability:** "God Class" corruption risk eliminated.
*   ‚úÖ **Scalability:** Modules can eventually become separate API endpoints.

---

## 6. Docker-Based Deployment (v3.0)

**Status:** Accepted

**Context:** Hugging Face Spaces environment can vary. Relying on "standard" python environment led to inconsistencies.

**Decision:** Use **Docker** as the deployment standard.

**Consequences:**
*   ‚úÖ **Reproducibility:** "Works on my machine" = Works on Cloud.
*   ‚úÖ **Control:** We define the OS, User ID, and exact library versions.
*   ‚ö†Ô∏è **Build Time:** Slower deployment (must build container).

---

## 7. Intrinsic Learning (Skill Graph)

**Status:** Accepted

**Context:** The interviewer was static. It didn't "improve" after seeing good answers.

**Decision:** Implement `LearningService` that extracts "Winning Strategies" from successful interviews (Score > 8/10) and stores them in `ReasoningBank`.

**Consequences:**
*   ‚úÖ **Adaptive:** System gets smarter over time.
*   ‚úÖ **Data-Driven:** Rubrics evolve based on real candidate data.

---

## 8. Time Test Diffusion (TTD) & Red Team (v3.3)

**Status:** Accepted

**Context:** Users reported repetitive questions. Simple substring matching was insufficient, and un-critiqued questions lacked depth.

**Decision:** Implement **TTD Algorithm** (Iterative Denoising) with an adversarial **Red Team Agent**.
*   **Red Team:** Attacks questions for repetition, bias, and ambiguity.
*   **Generate:** Parallel candidate generation + refinement loop.

**Consequences:**
*   ‚úÖ **Quality:** Questions are deeper and more robust.
*   ‚úÖ **Uniqueness:** Semantic deduplication ensures zero repeats.
*   ‚ö†Ô∏è **Latency:** Slight increase in generation time (2-3s).

---

## 9. Global Interview Quota (v3.3)

**Status:** Accepted

**Context:** Free Tier API usage needs strict control to prevent rate limits and abuse.

**Decision:** Implement **GlobalInterviewQuota** singleton.
*   **Limit:** 1 interview per day (UTC reset).
*   **Scope:** Application-wide (in-memory for MVP, extendable to Redis).

**Consequences:**
*   ‚úÖ **Cost Control:** Predictable API usage.
*   ‚úÖ **Stability:** Prevents "HuggingFace Quota Exceeded" errors.
*   ‚ö†Ô∏è **UX:** Friction for power users testing the system.
