# ðŸ“‹ Architecture Decision Records (ADR)

> **Last Updated:** 2025-12-12

## 1. Cloud-First Deployment

**Status:** Accepted

**Context:** The project was originally designed for local execution with Ollama. However, HuggingFace Spaces provides free hosting with serverless GPU inference.

**Decision:** Adopt a **cloud-first architecture** using HuggingFace Inference API as the primary deployment target.

**Consequences:**
- âœ… No local GPU required
- âœ… Free hosting on HuggingFace Spaces
- âœ… Automatic scaling
- âš ï¸ Requires internet connectivity
- âš ï¸ Subject to API rate limits

---

## 2. Single-Model Evaluation Strategy (Architecture Simplified)
**Status:** Accepted (Replaces Dual-Model)
**Context:** Multi-model inference (Mistral/Qwen) on Free Tier caused 500 errors ("Task not supported").
**Decision:** Standardize on **Meta-LLaMA-3 (8B)** for BOTH generation and evaluation.
**Consequences:**
- âœ… 100% API Stability (No "Task not supported" errors)
- âœ… Simplified Architecture (DRY)
- âš ï¸ Sacrifices nuanced scoring of larger models for reliability

---

## 3. 1-5 Scale Instead of 1-10

**Status:** Accepted

**Context:** Research (Prometheus, FARE) shows that 1-5 scales yield more reliable and consistent LLM evaluations.

**Decision:** Use **1-5 scoring scale** internally, convert to 1-10 for UI display.

**Consequences:**
- âœ… More consistent scores
- âœ… Easier rubric definitions
- âœ… Higher human correlation

---

## 4. Semantic Relevance Checking

**Status:** Accepted

**Context:** The AI was incorrectly scoring off-topic answers highly because heuristics only checked keywords.

**Decision:** Add **embedding-based semantic similarity** using Sentence Transformers.

**Consequences:**
- âœ… Detects off-topic answers accurately
- âœ… Cached embeddings for performance
- âš ï¸ Additional dependency (sentence-transformers)

---

## 5. Micro-Kernel Architecture (v3.0)

**Status:** Accepted

**Context:** The `AutonomousInterviewer` class grew into a "God Class" (1200+ lines), making testing and maintenance difficult. File corruption issues highlighted the need for separation.

**Decision:** Refactor into a **Micro-Service Architecture**:
*   **Orchestrator:** `AutonomousInterviewer` (Stateless Controller).
*   **State:** `SessionManager` (Isolated Logic).
*   **Cognition:** `CognitiveModules` (RAG, Critic, Learner).

**Consequences:**
*   âœ… **Testability:** Can verify `rag_service` without mocking the whole app.
*   âœ… **Stability:** "God Class" corruption risk eliminated.
*   âœ… **Scalability:** Modules can eventually become separate API endpoints.

---

## 6. Docker-Based Deployment (v3.0)

**Status:** Accepted

**Context:** Hugging Face Spaces environment can vary. Relying on "standard" python environment led to inconsistencies.

**Decision:** Use **Docker** as the deployment standard.

**Consequences:**
*   âœ… **Reproducibility:** "Works on my machine" = Works on Cloud.
*   âœ… **Control:** We define the OS, User ID, and exact library versions.
*   âš ï¸ **Build Time:** Slower deployment (must build container).

---

## 7. Intrinsic Learning (Skill Graph)

**Status:** Accepted

**Context:** The interviewer was static. It didn't "improve" after seeing good answers.

**Decision:** Implement `LearningService` that extracts "Winning Strategies" from successful interviews (Score > 8/10) and stores them in `ReasoningBank`.

**Consequences:**
*   âœ… **Adaptive:** System gets smarter over time.
*   âœ… **Data-Driven:** Rubrics evolve based on real candidate data.

